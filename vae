Klasičan autonenkoder ima enkoder koji mapira ulazne podatke u vektor sa specifičnim vrijednostima koji se onda dekodira u izlazni podatak.

Varijacijski autonekoder ima enkoder koji mapira ulazne podakte u vjerojatnosne distribucije umjest konkretne vrijednosti. Na taj način neko svojstvo opisujemo razdiobom. Npr neko svojstvo skrivenog vektora označava osmjeh. Umjesto da se koristi konkretan broj, prirodnije je da postoji razdioba koja opisuje taj osmjeh. Teško je reć modelu da samo neki broj predstavlja točno takav osmjeh. Takav model nebi bio baš generativne prirode. Nadalje, na ovaj način se forsiraju glatki prijelazi unutar svojstva. Bliske vrijednosti rezultiraju bliskim izlazima. Npr. za osmjeh, 0.80 i 0.81 bi bio veoma sličan osmjeh.

STATISTIKA

> potrebno izračunati p(z|x)
> p(x) veoma teško izračunati
> rješenje: aproksimiraj p(z|x) nekom distribucijom q(z|x)
> q(z|x) definirana tako da se može računati
> uvedi KL mrežu s kojom se minimizira razlika q(z|x) i p(z|x)
> to dovodi do izraza E(logp(x|z)) - KL(q(z|x)||p(z)) kojeg treba maksimizirati
	> prvi izraz predstavlja izglednost rekonstrukcije
	> drugi osigurava da je naučena razdioba q slična pravoj razdiobi p
> pretpostavlja se da je p(z) Gaussova razdioba.

IMPLEMENTACIJA

> enkoder izbacuje parametre koji opisuju razdiobu u skrivenom prostoru
> s obzirom da se pretpostavlja da je p(z) Gauss onda enkoder izbacuje 2 vektora koji opusuju sredinu i devijaciju
> radi backpropa uvodi se reparametrizacijski trik (inače se nebi moglo backpropat zbog uzorkovanja) 
