BILJEŠKE:

TODO:
Improved techniques for training GANs: https://arxiv.org/pdf/1606.03498.pdf
> U radu je opisano kako savršeno istrenirat MNIST i CIFAR-10
> Pokušat natjerat savršenu reprodukciju tih datasetova i opisat kako sam od osnovnih metoda (samo puknuo običnu konvolucijku i trenirao) došao do toga da super radi.
	> Osnovna metoda očito ne radi kao što se može vidit iz MNIST_DCGAN koje sam 
	trenirao 30 epoha i počeo je divergirat
	> Potrebno uvalit neki semi-supervised learning
	> Ne može se GAN samo tako pustit da se trenira

-------------------------------------------------------------------------------------------------

SIGMOID VS TANH
> ZAŠTO [0,1] faila dok [-1,1] radi super ?
> tanh vs sigmoid na izlazu generatora ?
> overfit ?

> nema veze šta sve prije nizamo relu, na kraju će se zadnji cijeli pozitivni izlaz iz relu (h) sudjelovat u h*w+b i to će postat ulaz za tanh i izlaz će opet bit [-1,1]

> TODO izvrtit na cloudu 30 epoha za sigmoid DCGAN

> RJEŠENJE: treniranje sa [0,1] overfita GAN, diskriminator postane predobar. Treba bolje izbalansirat izmjenično treniranje G i D.
	> Poboljšanje treniranja GAN-ova (https://arxiv.org/pdf/1606.03498.pdf)

--------------------------------------------------------------------------------------------------

> opisat MNIST dataset, kolko ima slika i tako
> trenirat mnist s gan-om i dcgan-om. unutar svakog vidit koji parametri najbolje odgovaraju (slojevi, relu/tanh/sigmoid, dropout, z_dim...). onda međusobno usporedit najbolje od gan-a i najbolje od dcgan-a.
> zašto ADAM optimizer ?
> zaključak da je dcgan bolji i koristit će se za druge slike
> kad ubacim neke kompleksnije slike rezultati mogu bit dosta loši, radi toga treba posegnut za nekim naprednijim tehnikama treniranja dcgan-ova ko šta je opisano u onom norveškom radu. npr dodavat šum u ulazne slike itd.

--------------------------------------------------------------------------------------------------

TESTIRANJE/EVALUACIJA (pitat mentora kolko i kako testirat !!!)
> splitat dataset na train i test pa onda u one grafove s greškama uvalit i test i train vrijednosti ?
> IDEJA za evaluaciju konačno istrenirane mreže: istrenirat mrežu koja dobro već zna razlikovat stvarne od lažnih slika ili skinut neku s interneta ili koristit mrežu koja dobro zna klasificirat pa vidit jel može klasificirat i rezultate dcgan-a. kakva je razlika ovog pristupa od onog kad se ove dvi uzastopno nadmeću ? jel mogu napravit konačnu evaluaciju na temelju spremanja d_lossova i g_lossova kroz treniranje kao što sada radim ? pogledat detaljnije norveški rad ?
> GAN-ove je na kraju najbolje ocjenit tako da ljudi pogledaju slike i vide imaju li smisla
> za MNIST bi mogao uzet mrežu koja jako dobro klasificira brojeve i onda vidjet može li isto tako dobro klasificirat i umjetno generirane brojeve
> SGAM algoritam (72. stranica norveškog rada) - uzastopno se treniraju i evaluiraju dvi mreže

> spremit DCGAN mrežu nakon što istreniram, prvo za MNIST

> objasnit dekonvoluciju (transposed convolution), čitav proces, batch normalization...
	https://towardsdatascience.com/up-sampling-with-transposed-convolution-9ae4f2df52d0
> zašto normalizacija: 
	https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c
	https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b
> što je dropout i zašto ga koristit

----------------------------------------------------------------------------------------------------
