[gan]
batch_size = 100
lr = 0.0002
train_epoch = 10
g_layers = 256,512,1024,784
d_layers = 1024,512,256,1
z_size = 100
drop_out = 0.3